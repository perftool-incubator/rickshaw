#!/usr/bin/env bash
# -*- mode: sh; indent-tabs-mode: nil; sh-basic-offset: 4 -*-
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=bash

# This script implements the 'osp' endpoint for rickshaw.  It runs 1 or more
# clients and servers as instances/VMs in an Openstack cluster.
#
# Usage:
# osp [--validate] --endpoint-opts=host=<host>,user=<user>,client:n-m,server:n-m 
#                    --run-id <id> --base-run-dir --image <location>
#                    --roadblock-server <host> --roadblock-id <id> --roadblock-passwd=<passwd>
#
# If --validate is used all options after client/server will be ignored
#

# Source the base file for common functions and config
this_endpoint_dir=$(dirname `readlink -e $0` | sed -e 'sX/binXX')
endpoint_base_dir=$(cd $this_endpoint_dir >/dev/null && cd .. && /bin/pwd)
if [ -e "$endpoint_base_dir/base" ]; then
    . "$endpoint_base_dir/base"
else
    echo "Could not find endpoint source file "$endpoint_base_dir/base", exiting"
    exit 1
fi

echo "#running osp endpoint"
clear_all_servers="1"
endpoint_name="osp"
instance_prefix="rickshaw"
base_osruntime_bootstrap="$endpoint_base_dir/osruntime-bootstrap"
vm_image="centos9"
vm_user="root"
#network="management"
network="public"
profiler_count=0
declare -A flavor
declare -A availability_zone
declare -A ips
declare -A active_compute_nodes
declare -A engine_hypervisor
osruntime[default]="podman"
availability_zone[default]="nova"
flavor[default]="m1.small"


function endpoint_osp_engine_init() {
    local engine_label count total_engines

    # globals used:
    # msg_file endpoint_run_dir clients servers profilers endpoint_label
    # host userenv os_runtime

    echo "Running endpoint_engine_init"
    total_engines=`echo "${#clients[@]} + ${#servers[@]} + ${#profilers[@]}" | bc` 
    if [ $total_engines -eq 0 ]; then
        echo "No engines, so not creating env-vars.json file(s)"
        return
    fi

    msg_file="$endpoint_run_dir/env-vars.json"
    count=0
    echo '[' >$msg_file

    for engine_label in ${clients[@]} ${servers[@]} ${profilers[@]}; do
        if [ $count -gt 0 ]; then
            printf "," >>$msg_file
        fi
        set_osruntime_numanode_cpupart ${engine_label}
        echo '{"recipient":{"type":"follower","id":"'$engine_label'"},"user-object":{"env-vars":{' >>$msg_file
        echo '"endpoint_label": "'$endpoint_label'",' >>$msg_file
        if [[ -v "engine_hypervisor[$engine_label]" ]]; then
            this_hypervisor_host=${engine_hypervisor[$engine_label]}
        else
            this_hypervisor_host="none"
        fi
        echo '"hypervisor_host": "'$this_hypervisor_host'",' >>$msg_file
        echo '"userenv": "'$userenv'",' >>$msg_file
        echo '"osruntime": "'$os_runtime'"' >>$msg_file
        echo '}}}' >>$msg_file

        let count=$count+1
    done
    echo ']' >>$msg_file
}

function endpoint_osp_test_stop() {
    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    echo "Running endpoint_osp_test_stop"

    # Delete network related openstack items here (router, floating ip, firewall?)
}

function endpoint_osp_test_start() {
    # This function runs right after a server starts any service and right before a client starts
    # and tries to contect the server's service.  The purpose of this function is to do any
    # work which ensures the client can contact the server.  In some cases there may be nothing
    # to do.  Regardless of the work, the endpoint needs to relay what IP & ports the client
    # needs to use in order to reach the server.  In some cases that may be the information the
    # server has provided to the endpoint, or this information has changed because the endpoint
    # created some sort of proxy to reach the server.

    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    local tx_msgs_dir="$1"; shift
    echo "Running endpoint_osp_test_start"
    # Creating any service or ingress only works if any servers provided information about its
    # IP and ports.
    local this_msg_file="${msgs_dir}/${test_id}:server-start-end.json"
    if [ -e $this_msg_file ]; then
        echo "Found $this_msg_file"
        # Extract the cs-label (server-n, client-y) the IP, and the ports this benchmark is using:
        # server-1 1.2.3.4 30002 30003
        cat $this_msg_file | jq -r '.received[] | if .payload.message.command == "user-object" and .payload.message."user-object".svc.ports then [ .payload.sender.id, .payload.message."user-object".svc.ip, .payload.message."user-object".svc.ports ] | flatten | tostring   else null end' | grep -v null | sed -e 's/"//g' -e 's/\[//' -e 's/\]//' -e 's/,/ /g' >"$endpoint_run_dir/ports.txt"

        while read -u 9 line; do
            echo "line: $line"
            # TODO: set up OSP network services here, like firewall, router, etc
        done 9< "$endpoint_run_dir/ports.txt"
    else
        echo "Did not find $this_msg_file"
    fi
}

function osp_req_check() {
    if [ -z "$host" ]; then
        exit_error "osp host is not defined"
    fi
    verify_ssh_login $user $host
    # TODO: source overcloudrc or equivalent init file to do osp stuff.  Error out if not found
    osp_cmd=". ./overcloudrc && openstack server list"
    do_ssh ${user}@${host} "$osp_cmd 2>&1" >/dev/null 2>&1
    rc=$?
    if [ $rc -gt 0 ]; then
        exit_error "Could not run 'openstack' on overcloud host: $osp_cmd"
    fi
    # Validation returns what clients and servers would be used and the userenv
    if [ "$do_validate" == 1 ]; then
        echo_clients_servers
        echo "userenv $userenv"
        exit
    fi
}

function process_osp_opts() {
    local endpoint_opts="$1"
    for opt in `echo $endpoint_opts | sed -e 's/,/ /g'`; do
        arg=`echo $opt| awk -F: '{print $1}'`
        # The $val may have : in it, so don't use awk to get only the second field
        val=`echo $opt | sed -e s/^$arg://`
        case "$arg" in


            # for arg = [flavor, availability-zone]:
            # option format:  arg:<engine-specifer>:<val>
            # <engine-specifer> can be 'default' to apply to any engine that is not explicitly specified
            # <engine-specifier> can be an engine type (client, server) and a '-', followed by range(s) of numbers:
            #   client-1-3+5-7+9-11   <-ranges must be separated with '+' and not ','
            # examples:
            # flavor:default:ospdev
            # availability-zone:client-1-6+10-16:nova
            flavor)
                store_vars $val flavor
                ;;
            availability-zone)
                store_vars $val availability_zone
                ;;


            disable-tools)
                disable_tools="$val"
                ;;
            ospconfig)
                ospconfig=$val
                ;;
            network)
                network=$val
                this_key=$(get_opt_field "${val}" "key")
                this_value=$(get_opt_field "${val}" "value")
                label=`echo $this_key | awk -F- '{print $1}'`
                range=`echo $this_key | sed -e s/$label-//`
                ;;
            client|server|clients|servers)
                addto_clients_servers "$arg" "$val"
                ;;
            host)
                host=$val
                if [ -z "$controller_ipaddr" ]; then
                    controller_ipaddr=`get_controller_ip $host`
                fi
                ;;
            controller-ip)
                controller_ipaddr=$val
                ;;
            user)
                user=$val
                ;;
            vm-user)
                vm_user=$val
                ;;
            vm-image)
                vm_image=$val
                ;;
            userenv)
                userenv=$val
                ;;
            *)
                if echo $arg | grep -q -- "="; then
                    echo "You can't use a \"=\" for assignment in endpoint options"
                    echo "You must use \":\", like `echo $arg | sed -e 's/=/:/'`"
                fi
                exit_error "osp endpoint option [$arg] not supported"
                ;;
        esac
    done
}

function create_remotehost_engines() {
    echo "create_remotehost_engines()"
}

function create_servers() {
    typeset -n ref1=$1; shift # caller-provided variable name (call-by-reference)
    ref1=""
    local instances=""

    ssh_id=$(sed -z 's/\n/\\n/g' ${config_dir}/rickshaw_id.rsa)

    # One openstack server (VM, instance, etc) is created per client and server benchmark engine
    # Servers are not created for collecting tools on compute, controller, network nodes.
    # An osruntime (chroot or podman container) will be created on each of those nodes via launch_osruntime()

    echo "vm_ssh_key_name: [$vm_ssh_key_name]"
    echo "vm_ssh_key_file: [$vm_ssh_key_file]"
    do_ssh ${user}@${host} "mkdir -p $vm_ssh_key_dir"
    echo "checking for existence of ssh key"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack keypair list --quote minimal -f csv | grep -v Name,Fingerprint" >${endpoint_run_dir}/openstack-keys.txt
    existing_key=`cat ${endpoint_run_dir}/openstack-keys.txt | awk -F, '{print $1}' | grep -v \"Name\" | grep $vm_ssh_key_name` 
    if [ "[$existing_key]" == "[$vm_ssh_key_name]" ]; then
        echo "deleting existing ssh key [$vm_ssh_key_name]"
        do_ssh ${user}@${host} "$osp_pre_cmd openstack keypair delete $vm_ssh_key_name" 
        echo "remaining keypairs"
        do_ssh ${user}@${host} "$osp_pre_cmd openstack keypair list --quote minimal -f csv"
    fi
    echo "creating new ssh key:"
    echo "[$osp_pre_cmd openstack keypair create $vm_ssh_key_name >$vm_ssh_key_file && chmod 600 $vm_ssh_key_file]"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack keypair create $vm_ssh_key_name >$vm_ssh_key_file && chmod 600 $vm_ssh_key_file"
    local osp_servers=""

    do_ssh ${user}@${host} "$osp_pre_cmd openstack flavor list -f value -c Name" >${endpoint_run_dir}/openstack-flavors.txt
    do_ssh ${user}@${host} "$osp_pre_cmd openstack image list -f value -c Name" >${endpoint_run_dir}/openstack-images.txt
    do_ssh ${user}@${host} "$osp_pre_cmd openstack network list -f value -c Name" >${endpoint_run_dir}/openstack-networks.txt

    if grep -q $network ${endpoint_run_dir}/openstack-networks.txt; then
        echo "Confirmed network [$network] is available"
    else
        abort_error "Network [$network] does not exist" endpoint-deploy-begin
    fi

    if [ "$clear_all_servers" == "1" ]; then # Clear all rickshaw servers, even from other run ids
        do_ssh ${user}@${host} "$osp_pre_cmd openstack server list -f value -c Name" >${endpoint_run_dir}/openstack-existing-servers.txt
        existing_servers=`cat ${endpoint_run_dir}/openstack-existing-servers.txt | grep rickshaw`
        if [ ! -z "$existing_servers" ]; then
            echo "deleting existing servers [$existing_servers]"
            do_ssh ${user}@${host} "$osp_pre_cmd openstack server delete $existing_servers" 
        fi
        do_ssh ${user}@${host} "$osp_pre_cmd openstack port list -f value -c Name" >${endpoint_run_dir}/openstack-existing-ports.txt
        existing_ports=`cat ${endpoint_run_dir}/openstack-existing-ports.txt | grep rickshaw`
        if [ ! -z "$existing_ports" ]; then
            echo "deleting existing ports [$existing_ports]"
            do_ssh ${user}@${host} "$osp_pre_cmd openstack port delete $existing_ports" 
        fi
    fi

    total_cpu_partitions=0
    set_total_cpupart
    for this_server in ${clients[@]} ${servers[@]}; do
        create_server $this_server
    done
    if [ "$disable_tools" == "1" ]; then
        return
    fi


    echo "profilers: ${profilers[@]}"
    # Run tool engines on any hypervisor hosts that have our VMs
    local image_list=""
    local disable_tools_list=""
    local engine_list=""
    local hypervisor_profilers=""
    for this_node in ${!active_compute_nodes[@]}; do
        add_profiler_engines compute hypervisor_profilers
        echo "hypervisor_profilers: $hypervisor_profilers"
        engine_list="$hypervisor_profilers"
        echo "engine_list: $engine_list"
        for this_engine in $engine_list; do
            get_image_name $this_engine this_image
            if [ -z "$this_image" ]; then
                abort_error "Could not find image for $this_engine" endpoint-deploy-begin
            fi
            image_list+=",$this_image"
            disable_tools_list+=",0" # any osruntime for a tool must have tools enabled
        done
        image_list=`echo $image_list | sed -e 's/^,//'`
        disable_tools_list=`echo $disable_tools_list | sed -e 's/^,//'`
        engine_list=`echo $engine_list | sed -e 's/ /,/g'`

        this_node_scp="scp $ssh_opts root@$this_node"
        this_osruntime_bootstrap="rickshaw-$run_id-$this_node-osruntime-bootstrap"
        echo "cpu_partitioning: [$cpu_partitioning]"
        echo "numa_node: [$numa_node]"
        echo "os_runtime: [$os_runtime]"
        pushd $endpoint_run_dir >/dev/null
        make_osruntime_boostrap_script\
            "$this_osruntime_bootstrap"\
            "$run_id"\
            "$controller_ipaddr"\
            "$endpoint_run_dir"\
            "$engine_list"\
            "$base_run_dir"\
            "0"\
            "$endpoint_label"\
            "podman"\
            "$max_sample_failures"\
            "$max_rb_attempts"\
            "$rb_passwd"\
            "$rb_id"\
            "$ssh_id"\
            "$image_list"\
            "$disable_tools_list"
        do_scp "" "$this_osruntime_bootstrap" "${user}@${host}" "~"
        if [ "$host" != "$this_node" ]; then
            echo "Copying bootstrap script from undercloud [$host] to compute node [$this_node]"
            echo "ssh_opts: $ssh_opts"
            do_ssh ${user}@${host} /bin/scp ./$this_osruntime_bootstrap root@$this_node:~/$this_osruntime_bootstrap
            echo "Starting bootstrap script on compute node [$this_node]"
            do_ssh ${user}@${host} /bin/ssh root@$this_node ./$this_osruntime_bootstrap
        else
            echo "Starting bootstrap script on all-in-one openstack node [$this_node]"
            do_ssh ${user}@${host} sudo ./$this_osruntime_bootstrap
        fi
        for this_engine in `echo $engine_list | sed -e 's/,/ /g'`; do
            ips[$this_engine]=$this_server_ip
        done
        popd >/dev/null
    done
    echo "profilers: ${profilers[@]}"
}


function create_server() {
    local cs_label=$1; shift

    local this_cs_type=`echo $cs_label | awk -F- '{print $1}'`
    local this_cs_id=`echo $cs_label | awk -F- '{print $2}'`
    local this_image=""
    local these_profilers=""
    local engine_list=""
    local image_list=""
    local disable_tools_list="1" # a client or server osruntime always has tools disabled

    if [ "$disable_tools" != "1" ]; then
        # Get the profilers needed to run with this client or server
        add_profiler_engines "$cs_label" these_profilers
    fi

    engine_list="$cs_label $these_profilers"
    echo "engine_list: $engine_list"
    for this_engine in $engine_list; do
        get_image_name $this_engine this_image
        if [ -z "$this_image" ]; then
            abort_error "Could not find image for $this_engine" endpoint-deploy-begin
        fi
        image_list+=",$this_image"
        disable_tools_list+=",0" # any osruntime for a tool must have tools enabled
    done
    image_list=`echo $image_list | sed -e 's/^,//'`
    engine_list=`echo $engine_list | sed -e 's/ /,/g'`

    echo "engines: $engine_list"
    echo "images: $image_list"

    local vm_name="rickshaw-$run_id-$cs_label"
    local mgmt_port_name="mgmt-$vm_name"
    local this_osruntime_bootstrap="$vm_name-osruntime-bootstrap"
    local this_availability_zone=""

    set +u
    if [ ! -z "${availability_zone[$cs_label]}" ]; then
        this_availability_zone=${availability_zone[$cs_label]}
    else
        this_availability_zone=${availability_zone[default]}
    fi

    local this_flavor=""
    if [ ! -z "${flavor[$cs_label]}" ]; then
        this_flavor=${flavor[$cs_label]}
    else
        this_flavor=${flavor[default]}
    fi
    set -u

    if grep -q $this_flavor ${endpoint_run_dir}/openstack-flavors.txt; then
        echo "Confirmed flavor [$this_flavor] is available"
    else
        abort_error "Flavor [$this_flavor] does not exist" endpoint-deploy-begin
    fi

    if grep -q $vm_image ${endpoint_run_dir}/openstack-images.txt; then
        echo "Confirmed image [$vm_image] is available"
    else
        abort_error "VM image [$vm_image] does not exist\nAvailable images: `cat ${endpoint_run_dir}/openstack-images.txt`" endpoint-deploy-begin
    fi

    if [ "$clear_all_servers" == "0" ]; then # Clear only servers with same run id
        existing_servers=`cat ${endpoint_run_dir}/openstack-existing-servers.txt | grep $vm_name`
        if [ ! -z "$existing_servers" ]; then
            echo "deleting existing server [$existing_servers]"
            do_ssh ${user}@${host} "$osp_pre_cmd openstack server delete $existing_servers" 
        fi
        existing_ports=`cat ${endpoint_run_dir}/openstack-existing-ports.txt | grep $vm_name`
        if [ ! -z "$existing_ports" ]; then
            echo "deleting existing ports [$existing_ports]"
            do_ssh ${user}@${host} "$osp_pre_cmd openstack port delete $existing_ports" 
        fi
    fi

    echo "creating openstack mgmt port for server $vm_name"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack port create --network $network --no-security-group --disable-port-security $mgmt_port_name"

    set_osruntime_numanode_cpupart $cs_label
    echo "cpu_partitioning: [$cpu_partitioning]"
    echo "numa_node: [$numa_node]"
    echo "os_runtime: [$os_runtime]"

    pushd $endpoint_run_dir >/dev/null
    make_osruntime_boostrap_script\
        "$this_osruntime_bootstrap"\
        "$run_id"\
        "$controller_ipaddr"\
        "$endpoint_run_dir"\
        "$engine_list"\
        "$base_run_dir"\
        "$cpu_partitioning"\
        "$endpoint_label"\
        "$os_runtime"\
        "$max_sample_failures"\
        "$max_rb_attempts"\
        "$rb_passwd"\
        "$rb_id"\
        "$ssh_id"\
        "$image_list"\
        "$disable_tools_list"
    do_scp "" "$this_osruntime_bootstrap" "${user}@${host}" "~"
    popd >/dev/null

    # Server is created with --user-data <osruntime-bootstrap-script>, and the server will run this script right after boot.
    echo "creating openstack server $vm_name"
    server_create_cmd="$osp_pre_cmd openstack server create --flavor $this_flavor --nic port-id=$mgmt_port_name --image $vm_image --availability-zone $this_availability_zone --key-name $vm_ssh_key_name --user-data $this_osruntime_bootstrap --key-name $vm_ssh_key_name $vm_name"
    echo "Going to run via ssh: $server_create_cmd"
    do_ssh ${user}@${host} $server_create_cmd >${endpoint_run_dir}/openstack-create-$vm_name.txt 2>&1
    rc=$?
    if [ $rc -ne 0 ]; then
        echo "openstack server create exit code: $rc"
        cat ${endpoint_run_dir}/openstack-create-$vm_name.txt
        abort_error "`cat ${endpoint_run_dir}/openstack-create-$vm_name.txt`" endpoint-deploy-begin
    fi

    # The following is necessary to get engine logs
    echo "getting openstack port information for $vm_name"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack port show $mgmt_port_name -f json" >${endpoint_run_dir}/openstack-port-$mgmt_port_name.json
    echo "finding server IP"
    this_server_ip=`jq -r .fixed_ips[0].ip_address ${endpoint_run_dir}/openstack-port-$mgmt_port_name.json`
    echo "this_server_ip: [$this_server_ip]"
    do_ssh ${user}@${host} "$osp_pre_cmd ssh-keygen -R $this_server_ip"
    osp_servers+=" $cs_label"
    for this_engine in `echo $engine_list | sed -e 's/,/ /g'`; do
        ips[$this_engine]=$this_server_ip
    done

    # Remember the compute nodes that are hosting VMs, so
    # a) tool-collection osruntimes can be launched on them later
    # b) hypervisor_host env var can be sent to the engines at engine-init roadblock
    this_compute_node=`do_ssh ${user}@${host} $osp_pre_cmd openstack server show $vm_name -f json | jq -r '."OS-EXT-SRV-ATTR:hypervisor_hostname"'`
    if [ "$this_compute_node" == "null" ]; then
        # Assume this is a all-in-one openstack and use the endpoint $host as the hypervisor
        this_compute_node=$host
    fi
    if [ "[$this_compute_node]" != "[]" ]; then
        active_compute_nodes[$this_compute_node]="1"
        for this_engine in `echo $engine_list | sed -e 's/,/ /g'`; do
            engine_hypervisor[$this_engine]=$this_compute_node
        done
    else
        echo "Something went wrong getting compute node for $vm_name, exiting"
    fi
}


function cleanup_osruntime() {
    local this_cs_label
    local vm_names=""
    local mgmt_port_names=""
    local this_osruntime_bootstrap
    echo "Going to delete VMs for these clients and servers: ${clients[@]} ${servers[@]}"
    for this_cs_label in ${clients[@]} ${servers[@]}; do
        vm_names+=" rickshaw-$run_id-$this_cs_label"
        mgmt_port_names+=" mgmt-rickshaw-$run_id-$this_cs_label"
    done
    echo "deletintg VM [$vm_names]"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack server delete $vm_names" >${endpoint_run_dir}/openstack-server-delete-vms.txt
    echo "deletintg network port [$mgmt_port_names]"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack port delete $mgmt_port_names" >${endpoint_run_dir}/openstack-port-delete-mgmt-ports.txt
    echo "deletintg keypair [$vm_ssh_key_name]"
    do_ssh ${user}@${host} "$osp_pre_cmd openstack keypair delete $vm_ssh_key_name" >${endpoint_run_dir}/openstack-keypair-delete-$vm_ssh_key_name.txt
    echo "deletintg keyfile [$vm_ssh_key_name]"
    do_ssh ${user}@${host} "rm -f $vm_ssh_key_file"
    echo "deleting osruntime-bootstrap scripts"
    do_ssh ${user}@${host} "rm -f *osruntime-bootstrap"
    for this_node in ${!active_compute_nodes[@]}; do
        this_osruntime_bootstrap="rickshaw-$run_id-$this_node-osruntime-bootstrap"
        do_ssh ${user}@${host} /bin/ssh root@$this_node /bin/rm ./$this_osruntime_bootstrap
    done

    do_ssh ${user}@${host} "$osp_pre_cmd openstack server list" >${endpoint_run_dir}/openstack-server-remaining.txt
    echo "remaining rickshaw openstack servers:"
    grep rickshaw ${endpoint_run_dir}/openstack-server-remaining.txt

    do_ssh ${user}@${host} "$osp_pre_cmd openstack port list" >${endpoint_run_dir}/openstack-port-remaining.txt
    echo "remaining rickshaw openstack ports:"
    grep rickshaw ${endpoint_run_dir}/openstack-port-remaining.txt

    return 0
}


function move_osp_logs() {
    echo "moving engine logs"
    local this_cs_label remote_cs_log_file container_name delete_remote_dir
    mkdir -p $engine_logs_dir
    #for this_cs_label in ${clients[@]} ${servers[@]} $new_osp_followers; do
    for this_cs_label in ${clients[@]} ${servers[@]} ${profilers[@]}; do
        echo "this_cs_label: [$this_cs_label]"
        if echo $this_cs_label | grep -q ^compute; then
            # This assumes user stack on undercloud can ssh passwordless to root@controllers
            this_cs_ssh="ssh $ssh_opts root@${ips[$this_cs_label]}"
        else
            this_cs_ssh="ssh $ssh_opts -i $vm_ssh_key_file $vm_user@${ips[$this_cs_label]}"
        fi
        remote_cs_log_file="$remote_logs_dir/$this_cs_label.txt"
        local_cs_log_file="$engine_logs_dir/$this_cs_label.txt"
        set_osruntime_numanode_cpupart $this_cs_label
        echo "os_runtime: [$os_runtime]"
        if [ "$os_runtime" == "chroot" ]; then
            do_ssh $user@$host $this_cs_ssh cat $remote_cs_log_file >$local_cs_log_file &
        elif [ "$os_runtime" == "podman" ]; then
            container_name="rickshaw_${run_id}_$this_cs_label"
            echo "do_ssh $user@$host $this_cs_ssh sudo podman logs ${container_name}"
            do_ssh $user@$host $this_cs_ssh sudo podman logs ${container_name} >$local_cs_log_file &
        fi
    done
    wait
}

function get_osp_config() {
    echo "getting OSP config"
    #TODO: get instances, networks, etc.
}

function endpoint_osp_sysinfo() {
    local remote_base_dir remote_dir local_dir
    remote_base_dir="/var/lib/crucible"
    remote_dir="${remote_base_dir}/${endpoint_label}_${run_id}"
    local_dir="${endpoint_run_dir}/sysinfo"

    mkdir ${local_dir}

    #TODO: get cluster version info, sosreport, etc
}

function endpoint_osp_cleanup() {
    move_osp_logs
    cleanup_osruntime
}

process_opts "$@"
process_common_endpoint_opts osp_opts $endpoint_opts
process_osp_opts $osp_opts
init_common_dirs
load_settings

remote_base_dir="/var/lib/crucible"
remote_dir="${remote_base_dir}/${endpoint_label}_${run_id}"
remote_cfg_dir="${remote_dir}/cfg"
remote_logs_dir="${remote_dir}/logs"
remote_data_dir="${remote_dir}/data/tmp"
vm_ssh_key_dir=".rickshaw"
vm_ssh_key_name="$run_id-ssh-key"
vm_ssh_key_file="$vm_ssh_key_dir/$vm_ssh_key_name.pem"
osp_pre_cmd=". ./overcloudrc >/dev/null 2>&1 && "

osp_req_check
base_req_check
get_osp_config

echo "This endpoint to run these clients: ${clients[@]}"
echo "This endpoint to run these servers: ${servers[@]}"
echo "This endpoint to run these profilers: ${profilers[@]}"

# All roadblock particpants are not determined until it is known
# where tools are run.  Once this is known, this information needs
# to be sent back to the controller.
openstack_servers=""
create_servers openstack_servers ${clients[@]} ${servers[@]} ${profilers[@]}
echo "These openstack servers were created: $openstack_servers"
process_roadblocks osp $new_followers
echo "endpoint finished"
