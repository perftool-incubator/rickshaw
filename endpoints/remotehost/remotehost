#!/bin/bash
# -*- mode: sh; indent-tabs-mode: nil; sh-basic-offset: 4 -*-
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=bash
set -u

# This script implements the 'remotehost' endpoint for rickshaw.  It runs 1 or more
# clients and servers for as many benchmark interations/samples as required
# for a single invocation of rickshaw.
#
#
# Usage: (as called by rickshaw-run)
#
# remotehost
# [--validate]
# --endpoint-label
# --run-id
# --base-run-dir
# --image
# --roadblock-server
# --roadblock-id
# --roadblock-passwd
# --endpoint-opts=client:n-m,o-p,server:n-m,o-p,host:<remote-host>,userenv:<distro>,host-mount:<dirpath>
#
# Note: When specifying a remotehost endpoint on an invocation of rickshaw-run
# (or crucible run <benchmark>) the following format is used:
#
# --endpoint remotehost,client:<range>,server:<range>,host:<remote-hostname>
#
# and the remaining options are handled by rickshaw-run
#
# If --validate is used all options after client/server will be ignored

this_endpoint_dir=$(dirname `readlink -e $0` | sed -e 'sX/binXX')
endpoint_base_dir=$(cd $this_endpoint_dir >/dev/null && cd .. && /bin/pwd)
if [ -e "$endpoint_base_dir/base" ]; then
    . "$endpoint_base_dir/base"
else
    echo "Could not find endpoint source file "$endpoint_base_dir/base", exiting"
    exit 1
    exit
fi

# globals (also check $endpoint_base_dir/base for others!!!)
chroot_rbind_mounts="proc dev sys lib/firmware lib/modules usr/src boot var/run"
endpoint_name="remotehost"
image_cache_size=3
declare -A osruntime
osruntime[default]="chroot"
host_mounts=""
hypervisor_host="none"
remote_base_dir="/var/lib/crucible"
remote_dir=""
remote_cfg_dir=""
remote_logs_dir=""
remote_data_dir=""
msg_file=""
novar=""

function endpoint_remotehost_engine_init() {
    local engine_label count

    # globals used:
    # msg_file endpoint_run_dir clients servers profilers endpoint_label
    # host hypervisor_host userenv os_runtime

    echo "Running endpoint_engine_init"
    echo "engines: [${clients[@]}${servers[@]}${profilers[@]}]"
    if [ "[${clients[@]}${servers[@]}${profilers[@]}]" == "[]" ]; then
        echo "No engines, so not creating env-vars.json file(s)"
        return
    fi

    msg_file="$endpoint_run_dir/env-vars.json"
    count=0
    echo '[' >$msg_file

    for engine_label in ${clients[@]} ${servers[@]} ${profilers[@]}; do
        if [ $count -gt 0 ]; then
            printf "," >>$msg_file
        fi
        set_osruntime_numanode_cpupart ${engine_label}
        echo '{"recipient":{"type":"follower","id":"'$engine_label'"},"user-object":{"env-vars":{' >>$msg_file
        echo '"endpoint_label": "'$endpoint_label'",' >>$msg_file
        echo '"hosted_by": "'$host'",' >>$msg_file
        echo '"hypervisor_host": "'$hypervisor_host'",' >>$msg_file
        echo '"userenv": "'$userenv'",' >>$msg_file
        echo '"osruntime": "'$os_runtime'"' >>$msg_file
        echo '}}}' >>$msg_file

        let count=$count+1
    done
    echo ']' >>$msg_file
}

function endpoint_remotehost_test_stop() {
    echo "Running endpoint_remotehost_test_stop"
}

function endpoint_remotehost_test_start() {
    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    local tx_msgs_dir="$1"; shift
    local this_msg_file="$msgs_dir/$test_id:endpoint-start.json"
    local line count name ip ports port_list client_outside_endpoint server_outside_endpoint matching_client

    # globals used:
    # endpoint_run_dir servers clients

    echo "Running endpoint_remotehost_test_start"

    if [ -e $this_msg_file ]; then
        echo "Found $this_msg_file"
        # We are looking for a specific type of message, where a server is providing a
        # { "user-object": { "svc": { "ip: "<ipaddr>", "ports": [ ... ] } } }
        # This is the only type of message that an endpoint processes.
        # The message must come from a benchmark-server hosted on *this* endpoint
        #
        # Extract the cs-label (server-n, client-y) and the ports this benchmark is using
        # server-1 30002 30003
        cat $this_msg_file | jq -r '.received[] | if .payload.message.command == "user-object" and .payload.message."user-object".svc.ports then [.payload.sender.id, .payload.message."user-object".svc.ip, .payload.message."user-object".svc.ports  ] | flatten | tostring else null end' | grep -v null | sed -e 's/"//g' -e 's/\[//' -e 's/\]//' -e 's/,/ /g' >"$endpoint_run_dir/ip-ports.txt"
        while read -u 9 line; do
            # For a benchmark server in a remotehost endpoint, the only
            # thing that might be necessary to allow access from a
            # client is to punch a hole in the firewall, if one exists.
            # The current implementation of this endpoint does not do
            # that yet.  The only function here is to relay the IP/port
            # information found in the received message to the client.
            echo "line: $line"
            name=`echo $line | awk '{print $1}'`
            line=`echo $line | sed -e s/^$name//`
            ip=`echo $line | awk '{print $1}'`
            line=`echo $line | sed -e s/^$ip//`
            ports="$line"
            port_list=""
            count=1
            for port in $ports; do
                if [ $count -gt 1 ]; then
                    port_list+=", $port"
                else
                    port_list="$port"
                fi
                let count=$count+1
            done

            server_outside_endpoint=1
            echo "servers from this endpoint: ${servers[@]}"
            if echo ${servers[@]} | grep -q $name; then
                echo "This server, $name, is running from this endpoint"
                server_outside_endpoint=0
            fi

            client_outside_endpoint=1
            matching_client=`echo $name | sed -e s/server/client/`
            if echo ${clients[@]} | grep -q $matching_client; then
                echo "Matching client, $matching_client, is running from this endpoint"
                client_outside_endpoint=0
            fi

            if [ $client_outside_endpoint -eq 1 -a $server_outside_endpoint -eq 0 ]; then
                echo "Going to punch hole through firewall (some day...)"
                # TODO: actually punch hole through firewall (also undo on endpoint_remotehost_test_stop)
                # Now we can construct a message to be sent to the client about the IP and ports for the server
                echo "Creating a message to send to the client ($matching_client) with IP and port info"
                echo -n '{"recipient":{"type":"follower","id":"client-' >"$tx_msgs_dir/service-ip-$name.json"
                echo $name | awk -F- '{print $2}' | tr -d "\n" >>"$tx_msgs_dir/service-ip-$name.json"
                echo -n '"},"user-object":{"svc":{"ip": "'$ip'", ' >>"$tx_msgs_dir/service-ip-$name.json"
                echo '"ports": ['$port_list']}}}' >>"$tx_msgs_dir/service-ip-$name.json"
            fi
        done 9< "$endpoint_run_dir/ip-ports.txt"
    else
        echo "Could not find $this_msg_file"
    fi
}

function cleanup_osruntime() {
    local container_name container_image engine_label data_file tools os_runtime tmp_engine_label

    # globals used:
    # user host clients servers profilers os_runtime endpoint_run_dir endpoint_base_dir chroot_rbind_mounts
    echo "Doing osruntime cleanup"
    echo
    echo "All mounts on this remote host:"
    do_ssh $user@$host mount
    echo
    echo "All podman pods:"
    do_ssh $user@$host podman ps --all
    echo
    echo "All podman container mounts:"
    do_ssh $user@$host podman mount
    echo

    for engine_label in ${clients[@]} ${servers[@]} ${profilers[@]}; do
        set_osruntime_numanode_cpupart $engine_label

        if [ "$os_runtime" == "chroot" ]; then
            data_file=$endpoint_run_dir/chroot-container-mount.txt
            if [ -e $data_file ]; then
                while read tmp_engine_label container_mount; do
                    if [ "$engine_label" == "$tmp_engine_label" ]; then
                        for fs in $chroot_rbind_mounts; do
                            echo "Removing $fs from $container_mount"
                            do_ssh $user@$host umount --verbose --recursive $container_mount/$fs
                        done
                    fi
                done < $data_file
            else
                echo "WARNING: the file with container base mount [$data_file] could not be found"
            fi

            data_file=$endpoint_run_dir/chroot-container-id.txt
            if [ -e $data_file ]; then
                while read tmp_engine_label container_id; do
                    if [ "$engine_label" == "$tmp_engine_label" ]; then
                        echo "Removing container with id [$container_id]"
                        do_ssh $user@$host podman rm $container_id
                    fi
                done < $data_file
            else
                echo "WARNING: the file with container base mount [$data_file] could not be found"
            fi
        elif [ "$os_runtime" == "podman" ]; then
            container_name="${run_id}_${engine_label}"
            do_ssh $user@$host podman rm $container_name
        else
            echo "WARNING: os_runtime $os_runtime not supported"
        fi
    done

    echo "Performing container image cache management:"
    ${endpoint_base_dir}/remotehost/container-image-manager --remote-host ${user}@${host} --cache-size ${image_cache_size} --debug 0
    echo

    echo "Remaining containers on this remote host:"
    do_ssh $user@$host podman ps --all
    echo

    echo "Remaining container mounts on this remote host:"
    do_ssh $user@$host podman mount
    echo

    echo "Remaining container images on this remote host:"
    do_ssh $user@$host podman images --all
    echo
}

function process_remotehost_opts() {
    local endpoint_opts this_opt arg val
    endpoint_opts="$1"
    echo "#remotehost_opts: [$endpoint_opts]"
    for this_opt in `echo $endpoint_opts | sed -e 's/,/ /g'`; do
        arg=`echo $this_opt | awk -F: '{print $1}'`
        # The $val may have : in it, so don't use awk to get only the second field
        val=`echo $this_opt | sed -e s/^$arg://`
        case "$arg" in
            client|server|clients|servers|profiler)
                addto_clients_servers "$arg" "$val"
                ;;
            userenv)
                userenv=$val
                ;;
            host)
                host=$val
                if [ -z "$controller_ipaddr" ]; then
                    controller_ipaddr=`get_controller_ip $host`
                fi
                ;;
            hypervisor-host)
                hypervisor_host=$val
                ;;
            controller-ip)
                controller_ipaddr=$val
                ;;
            user)
                user=$val
                ;;
            host-mount)
                host_mounts+=" $val"
                ;;
            disable-tools)
                disable_tools="$val"
                ;;
            image-cache-size)
                image_cache_size=$val
                ;;
            *)
                if echo $arg | grep -q -- "="; then
                    echo "You can't use a \"=\" for assignment in endpoint options"
                    echo "You must use \":\", like `echo $arg | sed -e 's/=/:/'`"
                fi
                exit_error "remotehost endpoint option [$arg] not supported"
                ;;
        esac
    done
    if [ "$do_validate" != "1" ]; then
        remote_base_dir="/var/lib/crucible"
        remote_dir="${remote_base_dir}/${endpoint_label}_${run_id}"
        remote_cfg_dir="${remote_dir}/cfg"
        remote_logs_dir="${remote_dir}/logs"
        remote_data_dir="${remote_dir}/data/tmp"
    fi
}

function remotehost_req_check() {
    verify_ssh_login $user $host
    do_ssh $user@$host podman --version >/dev/null 2>&1 ||\
        do_ssh $user@$host yum install -y podman >/dev/null 2>&1 ||\
        exit_error "Podman not installed and could not install it" 
    # Validation returns what clients and servers would be used and the userenv
    if [ "$do_validate" == 1 ]; then
        echo_clients_servers
        echo "userenv $userenv"
        exit
    fi
}

function stop_pod() {
    local engine_label=$1; shift

    container_name="${run_id}_${engine_label}"
    do_ssh $user@$host podman rm $container_name
}

function exec_pod() {
    local engine_label=$1; shift
    local image=$1; shift
    local container_name=${run_id}_${engine_label}
    local cmd oldIFS fs env_file arg value cs_rb_opt

    # globals used:
    # os_runtime cpu_partitioning numa_node controller_ipaddr ssh_id cs_rb_opts
    # endpoint_run_dir base_run_dir max_rb_attempts total_cpu_partitions
    # max_sample_failures host_mounts user host remote_cfg_dir cpu_part_idx

    set_osruntime_numanode_cpupart $engine_label

    env_file="${engine_label}_env.txt"

    # probably the essential info to get engine to start and do engine-init RB:
    echo "rickshaw_host=$controller_ipaddr"         >> $endpoint_run_dir/$env_file
    echo "cs_label=$engine_label"                   >> $endpoint_run_dir/$env_file
    echo "ssh_id=$ssh_id"                           >> $endpoint_run_dir/$env_file
    # roadblock opts like redis server
    for cs_rb_opt in $cs_rb_opts; do
        arg=$(echo $cs_rb_opt | awk -F'=' '{print $1}')
        value=$(echo $cs_rb_opt | awk -F'=' '{print $2}')
        arg=$(echo $arg | sed -e 's/^--//' -e 's/-/_/g' )
        echo "$arg=$value"                          >> $endpoint_run_dir/$env_file
    done

    # probably the vars that coule be moved to engine-init RB message:
    echo "endpoint_run_dir=$endpoint_run_dir"       >> $endpoint_run_dir/$env_file
    echo "base_run_dir=$base_run_dir"               >> $endpoint_run_dir/$env_file
    echo "endpoint=remotehost"                      >> $endpoint_run_dir/$env_file

    echo "max_sample_failures=$max_sample_failures" >> $endpoint_run_dir/$env_file
    # why is this not handled in cs_rb_opt?
    echo "max_rb_attempts=$max_rb_attempts"         >> $endpoint_run_dir/$env_file

    echo "cpu_partitioning=$cpu_partitioning"       >> ${endpoint_run_dir}/${env_file}
    if [ "$cpu_partitioning" == "1" ]; then
        echo "cpu_partitions=$total_cpu_partitions" >> $endpoint_run_dir/$env_file
        echo "cpu_partition_index=$cpu_part_idx"    >> ${endpoint_run_dir}/${env_file}
        let cpu_part_idx=$cpu_part_idx+1
    fi


    # client and server engines never run tools
    if echo $engine_label | grep -v -P '^profiler' >/dev/null; then
        echo "disable_tools=1"        >> $endpoint_run_dir/$env_file
    fi

    # Copy env-file so podman can use it on the remote host
    if pushd $endpoint_run_dir >/dev/null; then
        echo "Copying $endpoint_run_dir/$env_file to $user@$host:$remote_cfg_dir"
        do_scp "" "$env_file" "$user@$host" "$remote_cfg_dir"
        popd >/dev/null
    else
        echo "Failed to pushd to $endpoint_run_dir to scp env file"
        exit 1
    fi

    cmd="podman run"
    cmd+=" --detach=true"
    cmd+=" --name=$container_name"
    cmd+=" --env-file $remote_cfg_dir/$env_file"
    cmd+=" --privileged --ipc=host --pid=host --net=host --security-opt=label=disable"
    cmd+=" --mount=type=bind,source=$remote_data_dir,destination=/tmp"
    cmd+=" --mount=type=bind,source=/lib/firmware,destination=/lib/firmware"
    cmd+=" --mount=type=bind,source=/lib/modules,destination=/lib/modules"
    cmd+=" --mount=type=bind,source=/usr/src,destination=/usr/src"
    if [ "$host_mounts" != "" ]; then
        oldIFS=$IFS
        IFS=" "
        for fs in $host_mounts; do
            cmd+=" --mount=type=bind,source=$fs,destination=$fs"
        done
        IFS=$oldIFS
    fi
    cmd+=" $image"

    echo -e "About to run:\ndo_ssh $user@$host ${cmd}\n"
    do_ssh $user@$host "$cmd"
    ssh_rc=$?
    if [ $ssh_rc -gt 0 ]; then
        echo "running $os_runtime failed"
        exit 1
    fi
}

function pull_images() {
    local this_image=""

    echo "ensuring container image is pulled to $host"
    for image in ${bench_to_image[@]}; do
        do_ssh $user@$host podman pull $image
    done
    echo "Recording container image usage"
    for image in ${bench_to_image[@]}; do
        do_ssh $user@$host "echo '$image $(date -u +%s)' >> ${remote_base_dir}/remotehost-container-image-census"
        echo "$image" >>$endpoint_run_dir/chroot-container-image.txt
    done
}

function check_existing_container() {
    local container_name=$1; shift
    local existing_container

    # globals
    # user host

    existing_container=`do_ssh $user@$host podman ps --all --format "{{.Names}}" | grep ^$container_name$`
    if [ ! -z "$existing_container" ]; then
        echo "WARNING: found existing container '$existing_container', deleting"
        do_ssh $user@$host podman stop $container_name
        do_ssh $user@$host podman kill $container_name
        do_ssh $user@$host podman rm $container_name
    fi
}

function exec_chroot() {
    local engine_label=$1; shift
    local image=$1; shift
    local container_name=${run_id}_${engine_label}
    local container_id container_mount oldIFS base_cmd cs_cmd ssh_rc

    # globals used:
    # user host controller_ipaddr endpoint_run_dir cs_rb_opts base_run_dir
    # max_sample_failures max_rb_attempts total_cpu_partitions engine_script_start_timeout
    # os_runtime numa_node cpu_partitioning chroot_rbind_mounts cpu_part_idx

    set_osruntime_numanode_cpupart $engine_label
    echo "Preparing to chroot $engine_label"
    echo "Adding container image mount for chroot osruntime"
    container_id=$(do_ssh $user@$host podman create --name $container_name $image)
    echo "container_id: $container_id"
    echo "$engine_label $container_id" >>$endpoint_run_dir/chroot-container-id.txt
    container_mount=$(do_ssh $user@$host podman mount "$container_id")
    echo "container_mount: $container_mount"
    echo "$engine_label $container_mount" >>$endpoint_run_dir/chroot-container-mount.txt
    echo "container_name: $container_name"
    echo "$engine_label $container_name" >>$endpoint_run_dir/chroot-container-name.txt
    if [ ! -z "$container_mount" ]; then
        echo "Container mount: $container_mount"
        # Allow the user to more easily inspect failed runs
        echo "Mapping container /tmp to host $remote_data_dir"
        do_ssh $user@$host mkdir -p $container_mount/tmp
        do_ssh $user@$host mount --verbose --options bind $remote_data_dir $container_mount/tmp
        echo "Adding host directories to container mount"
        if [ "$host_mounts" != "" ]; then
            local oldIFS=$IFS
            IFS=" "
            for fs in $host_mounts; do
                chroot_rbind_mounts+=" $fs"
            done
            IFS=$oldIFS
        fi
        for fs in $chroot_rbind_mounts; do
            echo "Adding $fs to $container_mount"
            do_ssh $user@$host mkdir -p $container_mount/$fs
            do_ssh $user@$host mount --verbose --options rbind /$fs $container_mount/$fs
            do_ssh $user@$host mount --verbose --make-rslave $container_mount/$fs
            echo
        done
        # for chroot osruntime we can also simply copy the ssh key
        echo "Copying ssh key to $user@$host:$container_mount/tmp/ for chroot runtime"
        pushd "$config_dir" >/dev/null
        do_scp "" "rickshaw_id.rsa" "$user@$host" "$container_mount/tmp/"
        popd >/dev/null
        do_ssh $user@$host /bin/cp /etc/hosts $container_mount/etc/
        do_ssh $user@$host /bin/cp /etc/resolv.conf $container_mount/etc/
    else
        echo "Container mount not found, exiting"
        exit 1
    fi

    base_cmd="/usr/local/bin/bootstrap"
    base_cmd+=" --rickshaw-host=$controller_ipaddr"
    base_cmd+=" --endpoint-run-dir=$endpoint_run_dir"
    base_cmd+=" $cs_rb_opts"
    base_cmd+=" --cs-label=$engine_label"
    base_cmd+=" --base-run-dir=$base_run_dir"
    base_cmd+=" --endpoint=remotehost"
    base_cmd+=" --max-sample-failures=$max_sample_failures"
    base_cmd+=" --max-rb-attempts=$max_rb_attempts"

    base_cmd+=" --cpu-partitions=$total_cpu_partitions"
    if [ "$cpu_partitioning" == "1" ]; then
        base_cmd+=" --cpu-partitioning=$cpu_partitioning"
        base_cmd+=" --cpu-partition-index=$cpu_part_idx"
        let cpu_part_idx=$cpu_part_idx+1
    fi

    base_cmd+=" --engine-script-start-timeout=$engine_script_start_timeout"
    # chroot is not used for tools
    base_cmd+=" --disable-tools=1"
    if [ $numa_node -gt -1 ]; then
        base_cmd="numactl -N $numa_node -m $numa_node $base_cmd"
    fi

    # Note that --endpoint-run value must be hard-coded to /endpoint-run becaue of chroot
    # Same will be true for running podman
    cs_cmd="nohup chroot $container_mount $base_cmd >$remote_logs_dir/$engine_label.txt &"

    echo -e "About to run:\ndo_ssh $user@$host $cs_cmd\n"
    do_ssh $user@$host "$cs_cmd"
    ssh_rc=$?
    if [ $ssh_rc -gt 0 ]; then
        echo "running $os_runtime failed"
        exit 1
    fi
}


function launch_osruntimes() {
    local engine_label container_name this_image

    # globals used:
    # clients servers profilers os_runtime

    pull_images
    set_total_cpupart

    for engine_label in ${clients[@]} ${servers[@]} ${profilers[@]}; do
        container_name="${run_id}_${engine_label}"
        get_image_name $engine_label this_image
        check_existing_container $container_name
        set_osruntime_numanode_cpupart $engine_label
        echo "About to exec $engine_label via $os_runtime"
        if [ "$os_runtime" == "chroot" ]; then
            exec_chroot $engine_label $this_image
        elif [ "$os_runtime" == "podman" ]; then
            exec_pod $engine_label $this_image
        else
            exit_error "WARNING: os_runtime $os_runtime not supported"
        fi
    done
}

function move_remotehost_logs() {
    local engine_label remote_cs_log_file container_name delete_remote_dir log_file cmd_rc cmd_retries cmd_attempt
    local total_rc=0
    local delete_remote_dir=0

    # globals used:
    # clients servers profilers engine_logs_dir user host

    echo "Collecting engine logs:"
    # collect the client and server logs
    for engine_label in ${clients[@]} ${servers[@]} ${profilers[@]}; do
        set_osruntime_numanode_cpupart $engine_label
        log_file=${engine_label}.txt

        if [ "${os_runtime}" == "chroot" ]; then
            delete_remote_dir=1
            remote_cs_log_file="$remote_logs_dir/$log_file"
            do_scp "$user@$host" "$remote_cs_log_file" "" $engine_logs_dir
            cmd_rc=$?
            if [ $cmd_rc != 0 ]; then
                echo "Capturing chroot log for ${engine_label} failed with RC=${cmd_rc}"
            fi
            (( total_rc += $cmd_rc ))
        elif [ "$os_runtime" == "podman" ]; then
            container_name="${run_id}_${engine_label}"
            # implementing retry logic here because it is possible for
            # 'podman logs' to fail due to lock contention when podman
            # is under heavy load
            cmd_retries=5
            cmd_attempt=1
            cmd_rc=1
            while [ $cmd_rc != 0 -a $cmd_attempt -le $cmd_retries ]; do
                do_ssh $user@$host podman logs --timestamps $container_name > "$engine_logs_dir/$log_file" 2>&1
                cmd_rc=$?
                if [ $cmd_rc != 0 ]; then
                    echo "Capturing podman log for ${engine_label} failed with RC=${cmd_rc} on attempt ${cmd_attempt} of ${cmd_retries}"
                    (( cmd_attempt += 1 ))
                fi
            done
            (( total_rc += $cmd_rc ))
        else
            echo "WARNING: os_runtime $os_runtime not supported"
        fi
    done

    if [ "$delete_remote_dir" == "1" -a $total_rc == 0 ]; then
        echo "Deleting remote directory:"
        do_ssh $user@$host /bin/rm -rv $remote_dir
        cmd_rc=$?
        if [ $cmd_rc != 0 ]; then
            echo "Deleting remote directory failed with RC=${cmd_rc}"
        fi
        (( total_rc += $cmd_rc ))
    fi

    if [ $total_rc -gt 0 ]; then
        echo "WARNING: some or all of move_remotehost_logs() failed"
    fi
    return $total_rc
}

function endpoint_remotehost_cleanup() {
    local log_rc cleanup_rc

    # globals
    # <none>

    move_remotehost_logs
    log_rc=$?

    cleanup_osruntime
    cleanup_rc=$?

    return $(( $log_rc + $cleanup_rc ))
}

function endpoint_remotehost_sysinfo() {
    local local_dir="$endpoint_run_dir/sysinfo"
    local packrat_rc=0

    # globals used:
    # endpoint_run_dir user host

    mkdir $local_dir

    do_scp "" "$packrat_dir/packrat" "$user@$host" "$remote_dir"
    (( packrat_rc += $? ))

    do_ssh $user@$host mkdir -p $remote_dir/sysinfo
    (( packrat_rc += $? ))

    do_ssh $user@$host $remote_dir/packrat $remote_dir/sysinfo
    (( packrat_rc += $? ))

    do_scp "$user@$host" "$remote_dir/sysinfo/packrat-archive" "" "$local_dir"
    (( packrat_rc += $? ))

    do_ssh $user@$host rm -Rf $remote_dir/packrat $remote_dir/sysinfo
    (( packrat_rc += $? ))

    return $packrat_rc
}

function set_ssh_id() {
    # globals used:
    # config_dir ssh_id

    if [ ! -f $config_dir/rickshaw_id.rsa ]; then
        echo "could not find $config_dir/rickshaw_id.rsa"
        exit 1
    fi
    ssh_id=$(sed -z 's/\n/\\n/g' $config_dir/rickshaw_id.rsa)
}

function init_remotehost_dirs() {
    # globals used:
    # do_validate user host remote_cfg_dir remote_logs_dir remote_data_dir

    # create working directories
    if [ "$do_validate" != "1" ]; then
        do_ssh $user@$host /bin/mkdir -p $remote_cfg_dir
        do_ssh $user@$host /bin/mkdir -p $remote_logs_dir
        do_ssh $user@$host /bin/mkdir -p $remote_data_dir
    fi
}

process_opts $@
process_common_endpoint_opts rh_opts $endpoint_opts
process_remotehost_opts $rh_opts
init_common_dirs
init_remotehost_dirs
load_settings
remotehost_req_check
set_ssh_id
base_req_check
# Remotehost tool collection only needs first engine to determine profiler engines
first_engine=`echo ${clients[@]} ${servers[@]} ${profilers[@]} | awk '{print $1}'`
if [ -z "$first_engine" ]; then
    # If  empty, that can mean only one thing: this remotehost
    # has no clients and servers and used profiler:n
    first_engine="profiler"
fi
add_profiler_engines "$first_engine" novar
launch_osruntimes
process_roadblocks remotehost $new_followers
