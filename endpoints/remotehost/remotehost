#!/bin/bash
# -*- mode: sh; indent-tabs-mode: nil; sh-basic-offset: 4 -*-
# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4 filetype=bash
set -u


# This script implements the 'remotehost' endpoint for rickshaw.  It runs 1 or more
# clients and servers for as many benchmark interations/samples as required
# for a single invocation of rickshaw.
# 
#
# Usage: (as called by rickshaw-run)
#
# remotehost
# [--validate]
# --endpoint-label
# --run-id
# --base-run-dir
# --image
# --roadblock-server
# --roadblock-id
# --roadblock-passwd
# --endpoint-opts=client:n-m,o-p,server:n-m,o-p,host:<remote-host>,userenv:<distro>
#
# Note: When specifying a remotehost endpoint on an invocation of rickshaw-run
# (or crucible run <benchmark>) the following format is used:
#
# --endpoint remotehost,client:<range>,server:<range>,host:<remote-hostname>
#
# and the remaining options are handled by rickshaw-run
#
# If --validate is used all options after client/server will be ignored

this_endpoint_dir=$(dirname `readlink -e $0` | sed -e 'sX/binXX')
endpoint_base_dir=$(cd $this_endpoint_dir >/dev/null && cd .. && /bin/pwd)
if [ -e "$endpoint_base_dir/base" ]; then
    . "$endpoint_base_dir/base"
else
    echo "Could not find endpoint source file "$endpoint_base_dir/base", exiting"
    exit 1
    exit
fi

chroot_rbind_mounts="proc dev sys lib/modules usr/src boot"

endpoint_name="remotehost"
osruntime="chroot"
userenv="rhubi8"
user="root"

ssh_opts="-o StrictHostKeyChecking=no -o PasswordAuthentication=no"
declare -A cpuPartitioning
declare -A numaNode

function endpoint_remotehost_test_stop() {
    echo "Running endpoint_remotehost_test_stop"
}

function endpoint_remotehost_test_start() {
    local msgs_dir="$1"; shift
    local test_id="$1"; shift
    local tx_msgs_dir="$1"; shift
    echo "Running endpoint_remotehost_test_start"

    local this_msg_file="$msgs_dir/$test_id:endpoint-start.json"
    if [ -e $this_msg_file ]; then
        echo "Found $this_msg_file"
        # We are looking for a specific type of message, where a server is providing a
        # { "user-object": { "svc": { "ip: "<ipaddr>", "ports": [ ... ] } } }
        # This is the only type of message that an endpoint processes.
        # The message must come from a benchmark-server hosted on *this* endpoint
        #
        # Extract the cs-label (server-n, client-y) and the ports this benchmark is using
        # server-1 30002 30003
        cat $this_msg_file | jq -r '.received[] | if .payload.message.command == "user-object" and .payload.message."user-object".svc.ports then [.payload.sender.id, .payload.message."user-object".svc.ip, .payload.message."user-object".svc.ports  ] | flatten | tostring else null end' | grep -v null | sed -e 's/"//g' -e 's/\[//' -e 's/\]//' -e 's/,/ /g' >"$endpoint_run_dir/ip-ports.txt"
        while read -u 9 line; do
            # For a benchmark server in a remotehost endpoint, the only
            # thing that might be necessary to allow access from a
            # client is to punch a hole in the firewall, if one exists.
            # The current implementation of this endpoint does not do
            # that yet.  The only function here is to relay the IP/port
            # information found in the received message to the client.
            echo "line: $line"
            local name=`echo $line | awk '{print $1}'`
            line=`echo $line | sed -e s/^$name//`
            local ip=`echo $line | awk '{print $1}'`
            line=`echo $line | sed -e s/^$ip//`
            local ports="$line"
            local port_list=""
            local count=1
            for port in $ports; do
                if [ $count -gt 1 ]; then
                    port_list+=", $port"
                else
                    port_list="$port"
                fi
                let count=$count+1
            done

            local server_outside_endpoint=1
            echo "servers from this endpoint: ${servers[@]}"
            if echo ${servers[@]} | grep -q $name; then
                echo "This server, $name, is running from this endpoint"
                server_outside_endpoint=0
            fi

            local client_outside_endpoint=1
            matching_client=`echo $name | sed -e s/server/client/`
            if echo ${clients[@]} | grep -q $matching_client; then
                echo "Matching client, $matching_client, is running from this endpoint"
                client_outside_endpoint=0
            fi

            if [ $client_outside_endpoint -eq 1 -a $server_outside_endpoint -eq 0 ]; then
                echo "Going to punch hole through firewall (some day...)"
                # TODO: actually punch hole through firewall (also undo on endpoint_remotehost_test_stop)
                # Now we can construct a message to be sent to the client about the IP and ports for the server
                echo "Creating a message to send to the client ($matching_client) with IP and port info"
                echo -n '{"recipient":{"type":"follower","id":"client-' >"$tx_msgs_dir/service-ip-$name.json"
                echo $name | awk -F- '{print $2}' | tr -d "\n" >>"$tx_msgs_dir/service-ip-$name.json"
                echo -n '"},"user-object":{"svc":{"ip": "'$ip'", ' >>"$tx_msgs_dir/service-ip-$name.json"
                echo '"ports": ['$port_list']}}}' >>"$tx_msgs_dir/service-ip-$name.json"
            fi
        done 9< "$endpoint_run_dir/ip-ports.txt"
    else
        echo "Could not find $this_msg_file"
    fi
}

function do_ssh() {
    local user_host user host password ssh_cmd full_ssh_cmd
    user_host=$1; shift
    user=`echo $user_host | awk -F@ '{print $1}'`
    host=`echo $user_host | awk -F@ '{print $2}'`
    ssh_cmd=""
    full_ssh_cmd=""
    if [ -z "$user" ]; then
        exit_error "do_ssh: user was blank: $user_host"
    fi
    if [ -z "$host" ]; then
        exit_error "do_ssh: host was blank: $user_host"
    fi
    if [ "$user" != "root" ]; then
        ssh_cmd="ssh $ssh_opts $user_host sudo bash -c \"$@\""
    else
        ssh_cmd="ssh $ssh_opts $user_host $@"
    fi
    if [ -n "$password" ]; then
         full_ssh_cmd="sshpass -p $password $ssh_cmd"
    else
         full_ssh_cmd="$ssh_cmd"
    fi

    $full_ssh_cmd
    local rc=$?
    return $rc
}

function do_scp() {
    # The following allows for using a non-root user>
    # If a non-root user is used, that user must have root-priv
    # no password prompt required.
    local src dst dst_sudo_cmd dst_path dst_user_host dst_user dst_cmd
    local src_sudo_cmd src_path src_user_host src_user src_sudo_cmd src_cmd
    src=$1; shift # [<user>@<host>:]<source> source can be a dir or file
                        # If a dir, the full dir is used when copied to the destination
    dst=$1; shift # [<user>@<host>:]<destination> destination should be a dir, not a file

    if echo $dst | grep -q -- "@"; then
        dst_sudo_cmd=""
        dst_path=`echo $dst | awk -F: '{print $2}'`
        dst_user_host=`echo $dst | awk -F: '{print $1}'`
        dst_user=`echo $dst_user_host | awk -F@ '{print $1}'`
        if [ "$dst_user" != "root" ]; then
            local dst_sudo_cmd="sudo"
        fi
        dst_cmd="ssh $ssh_opts $dst_user_host $dst_sudo_cmd tar -C $dst_path -xf -"
    else
        dst_cmd="tar -C $dst -xf -"
    fi

    if echo $src | grep -q -- "@"; then
        src_sudo_cmd=""
        src_path=`echo $src | awk -F: '{print $2}'`
        src_user_host=`echo $src | awk -F: '{print $1}'`
        src_user=`echo $src_user_host | awk -F@ '{print $1}'`
        if [ "$src_user" != "root" ]; then
            src_sudo_cmd="sudo"
        fi
        src_cmd="ssh $ssh_opts $src_user_host $src_sudo_cmd tar -cf - $src_path"
    else
        src_cmd="tar -cf - $src"
    fi

    $src_cmd | $dst_cmd
}

function cleanup_osruntime() {
    local container_name container_image
    echo "Doing osruntime cleanup"
    echo
    echo "All mounts on this remote host:"
    do_ssh $user@$host mount
    echo
    echo "All podman pods:"
    do_ssh $user@$host podman ps --all
    echo
    echo "All podman container mounts:"
    do_ssh $user@$host podman mount
    echo
    container_name="${endpoint_label}_${run_id}"
    if [ "$osruntime" == "chroot" ]; then

        if [ -e $endpoint_run_dir/chroot-container-mount.txt ]; then
            container_mount=`cat $endpoint_run_dir/chroot-container-mount.txt`
            for fs in ${chroot_rbind_mounts}; do
                echo "Removing ${fs} from ${container_mount}"
                do_ssh $user@$host umount --verbose --recursive ${container_mount}/${fs}
                echo
            done
            echo "Unmounting container base mount [$container_mount] for chroot using container [$container_name]"
            do_ssh $user@$host podman umount $container_name
        else
            echo "WARNING: the file with container base mount [$endpoint_run_dir/chroot-container-mount.txt] could not be found"
        fi
    #elif [ "${osruntime}" == "podman" ]; then
        # podman specific things would go here...
    fi

    echo "Removing container with name [$container_name]"
    do_ssh $user@$host podman rm $container_name

    if [ -e $endpoint_run_dir/chroot-container-image.txt ]; then
        container_image=`cat $endpoint_run_dir/chroot-container-image.txt`
        echo "Removing container image [$container_image]"
        do_ssh $user@$host podman rmi $container_image
    else
        echo "WARNING: container image file [$endpoint_run_dir/chroot-container-image.txt] could not be found"
    fi

    echo "Remaining containers on this remote host:"
    do_ssh $user@$host podman ps --all
    echo "Remaining container mounts on this remote host:"
    do_ssh $user@$host podman mount
    echo "Remaining container images on this remote host:"
    do_ssh $user@$host podman images --all
    echo
}

function process_remotehost_opts() {
    local endpoint_opts this_opt arg val
    endpoint_opts="$1"
    for this_opt in `echo $endpoint_opts | sed -e 's/,/ /g'`; do
        arg=`echo $this_opt | awk -F: '{print $1}'`
        # The $val may have : in it, so don't use awk to get only the second field
        val=`echo $this_opt | sed -e s/^$arg://`
        case "$arg" in
            client|server|clients|servers)
                addto_clients_servers "$arg" "$val"
                ;;
            osruntime)
                case "$val" in
                    builtin|chroot|podman)
                        osruntime=$val
                        ;;
                    *)
                        exit_error "osruntime $val not supported"
                        ;;
                esac
                ;;
            numa-node)
                # node-node is per engine:
                # option format:: numa-node:<engine-name>:<value>
                # <engine-name> can be 'default' to apply to any engine that is not explicitly specified
                #TODO: validate correct format of <client-server-label>
                name=`echo $val | awk -F: '{ print $1 }'`
                value=`echo $val | awk -F: '{ print $2 }'`
                if [ ! -z "$name}" -a ! -z "$value" ]; then
                    numaNode[$name]=$value
                else
                    exit_error "Could not properly decode numa-node for '$val'"
                fi
                ;;
            userenv)
                userenv=$val
                ;;
            host)
                host=$val
                if [ -z "$controller_ipaddr" ]; then
                    controller_ipaddr=`get_controller_ip $host`
                fi
                ;;
            controller-ip)
                controller_ipaddr=$val
                ;;
            user)
                user=$val
                ;;
            password)
                password=$val
                ;;
            cpu-partitioning)
                # cpu-partitioning is per engine:
                # option format:: cpu-partitioning:<engine-name>:<value>
                # <engine-name> can be 'default' to apply to any engine that is no explicitly specified
                #TODO: validate correct format of <client-server-label>
                name=`echo $val | awk -F: '{ print $1 }'`
                value=`echo $val | awk -F: '{ print $2 }'`
                if [ ! -z "$name}" -a ! -z "$value" ]; then
                    cpuPartitioning[$name]=$value
                else
                    exit_error "Could not properly decode cpu-partitioning for '$val'"
                fi
                ;;
            *)
                if echo $arg | grep -q -- "="; then
                    echo "You can't use a \"=\" for assignment in endpoint options"
                    echo "You must use \":\", like `echo $arg | sed -e 's/=/:/'`"
                fi
                exit_error "remotehost endpoint option [$arg] not supported"
                ;;
        esac
    done
    if [ "$do_validate" != "1" ]; then
        remote_dir="/var/lib/crucible/${endpoint_label}_${run_id}"
        remote_cfg_dir="${remote_dir}/cfg"
        remote_logs_dir="${remote_dir}/logs"
        remote_data_dir="${remote_dir}/data/tmp"
    fi
}

function remotehost_req_check() {
    do_ssh $user@$host uptime >/dev/null || exit_error "Could not ssh to $host"
    do_ssh $user@$host podman --version >/dev/null 2>&1 ||\
        do_ssh $user@$host yum install -y podman >/dev/null 2>&1 ||\
        exit_error "Podman not installed and could not install it" 
    # Validation returns what clients and servers would be used and the userenv
    if [ "$do_validate" == 1 ]; then
        echo_clients_servers
        echo "userenv $userenv"
        exit
    fi
}

function launch_osruntime() {
    local this_cs_label this_cs_log_file base_cmd cs_cmd cs_rb_env env_file
    local env_opts existing_container container_id container_mount container_name fs
    echo "osruntime: $osruntime"

    # create working directories
    do_ssh $user@$host /bin/mkdir -p $remote_cfg_dir
    do_ssh $user@$host /bin/mkdir -p $remote_logs_dir
    do_ssh $user@$host /bin/mkdir -p $remote_data_dir

    echo "ensuring container image is pulled to $host"
    do_ssh $user@$host podman pull $image
    container_name="${endpoint_label}_${run_id}"
    existing_container=`do_ssh $user@$host podman ps --all --format "{{.Names}}" | grep ^$container_name$`
    if [ ! -z "$existing_container" ]; then
        echo "WARNING: found existing container '$existing_container', deleting"
        do_ssh $user@$host podman rm $container_name
    fi
    echo "$image" >$endpoint_run_dir/chroot-container-image.txt
    if [ "$osruntime" == "chroot" ]; then
        echo "Adding mount for chroot osruntime"
        container_id=`do_ssh $user@$host podman create --name $container_name $image`
        echo "$container_id"
        container_mount=`do_ssh $user@$host podman mount "$container_id"`
        echo "$container_id" >$endpoint_run_dir/chroot-container-id.txt
        echo "$container_mount" >$endpoint_run_dir/chroot-container-mount.txt
        if [ ! -z "$container_mount" ]; then
            echo "Container mount: $container_mount"
            # Allow the user to more easily inspect failed runs
            echo "Mapping container /tmp to host $remote_data_dir"
            do_ssh $user@$host mkdir -p $container_mount/tmp
            do_ssh $user@$host mount --verbose --options bind $remote_data_dir $container_mount/tmp
            echo "Adding host directories to container mount"
            for fs in ${chroot_rbind_mounts}; do
                echo "Adding ${fs} to ${container_mount}"
                do_ssh $user@$host mkdir -p $container_mount/$fs
                do_ssh $user@$host mount --verbose --options rbind /$fs $container_mount/$fs
                do_ssh $user@$host mount --verbose --make-rslave $container_mount/$fs
                echo
            done
            # for chroot osruntime we can also simply copy the ssh key
            echo "Copying ssh key to $user@$host:$container_mount/tmp/ for chroot runtime"
            pushd "$config_dir" >/dev/null
            do_scp "rickshaw_id.rsa" "$user@$host:$container_mount/tmp/"
            popd >/dev/null
            do_ssh $user@$host /bin/cp /etc/hosts $container_mount/etc/
            do_ssh $user@$host /bin/cp /etc/resolv.conf $container_mount/etc/
        else
            echo "Container mount not found, exiting"
            exit 1
        fi
    fi

    # For each client and server launch the actual script which will run it.
    count=1
    for this_cs_label in ${clients[@]} ${servers[@]}; do
        this_cs_log_file="$this_cs_label.txt"

        set +u
        cpu_partitioning=0
        if [ ! -z "${cpuPartitioning[$this_cs_label]}" ]; then
            cpu_partitioning=${cpuPartitioning[$this_cs_label]}
        elif [ ! -z "${cpuPartitioning[default]}" ]; then
            cpu_partitioning=${cpuPartitioning[default]}
        fi
        set -u

        set +u
        numa_node=-1
        if [ ! -z "${numaNode[$this_cs_label]}" ]; then
            numa_node=${numaNode[$this_cs_label]}
        elif [ ! -z "${numaNode[default]}" ]; then
            numa_node=${numaNode[default]}
        fi
        set -u

        if [ "$osruntime" == "chroot" ]; then
            echo "using chroot"

            base_cmd="/usr/local/bin/bootstrap"
            base_cmd+=" --rickshaw-host=$controller_ipaddr"
            base_cmd+=" --endpoint-run-dir=$endpoint_run_dir"
            base_cmd+=" $cs_rb_opts"
            base_cmd+=" --cs-label=$this_cs_label"
            base_cmd+=" --base-run-dir=$base_run_dir"
            base_cmd+=" --endpoint=remotehost"
            base_cmd+=" --osruntime=$osruntime"
            base_cmd+=" --max-sample-failures=$max_sample_failures"
            base_cmd+=" --max-rb-attempts=$max_rb_attempts"
            base_cmd+=" --cpu-partitioning=$cpu_partitioning"
            if [ $numa_node -gt -1 ]; then
                base_cmd="numactl -N $numa_node -m $numa_node $base_cmd"
            fi
            if [ $count -gt 1 ]; then
                # Only the first client/server needs to run tools
                echo "Skipping tools execution on $this_cs_label because a previous client/server is running tools on this host"
                base_cmd+=" --disable-tools=1"
            fi

            # Note that --endpoint-run value must be hard-coded to /endpoint-run becaue of chroot
            # Same will be true for running podman
            cs_cmd="nohup chroot $container_mount $base_cmd >$remote_logs_dir/$this_cs_log_file &"
        elif [ "$osruntime" == "podman" ]; then
            echo "using podman"

            env_file="${this_cs_label}_env.txt"

            ssh_id=$(sed -z 's/\n/\\n/g' ${config_dir}/rickshaw_id.rsa)

            echo "rickshaw_host=$controller_ipaddr"         >> ${endpoint_run_dir}/${env_file}
            echo "endpoint_run_dir=$endpoint_run_dir"       >> ${endpoint_run_dir}/${env_file}
            echo "cs_label=$this_cs_label"                  >> ${endpoint_run_dir}/${env_file}
            echo "base_run_dir=$base_run_dir"               >> ${endpoint_run_dir}/${env_file}
            echo "cpu_partitioning=$cpu_partitioning"       >> ${endpoint_run_dir}/${env_file}
            echo "endpoint=remotehost"                      >> ${endpoint_run_dir}/${env_file}
            echo "osruntime=$osruntime"                     >> ${endpoint_run_dir}/${env_file}
            echo "max_sample_failures=$max_sample_failures" >> ${endpoint_run_dir}/${env_file}
            echo "max_rb_attempts=$max_rb_attempts"         >> ${endpoint_run_dir}/${env_file}
            echo "ssh_id=${ssh_id}"                         >> ${endpoint_run_dir}/${env_file}

            for cs_rb_opt in $cs_rb_opts; do
                arg=$(echo $cs_rb_opt | awk -F'=' '{print $1}')
                value=$(echo $cs_rb_opt | awk -F'=' '{print $2}')

                arg=$(echo ${arg} | sed -e 's/^--//' -e 's/-/_/g' )

                echo "${arg}=${value}"                      >> ${endpoint_run_dir}/${env_file}
            done

            if pushd ${endpoint_run_dir} >/dev/null; then
                echo "Copying ${endpoint_run_dir}/${env_file} to ${user}@${host}:${remote_cfg_dir}"
                do_scp "${env_file}" "${user}@${host}:${remote_cfg_dir}"

                popd >/dev/null
            else
                echo "Failed to pushd to ${endpoint_run_dir} to scp env file"
                exit 1
            fi

            cs_cmd="podman run"
            cs_cmd+=" --detach=true"
            cs_cmd+=" --name=${container_name}"
            cs_cmd+=" --env-file ${remote_cfg_dir}/${env_file}"
            cs_cmd+=" --privileged"
            cs_cmd+=" --ipc=host"
            cs_cmd+=" --pid=host"
            cs_cmd+=" --net=host"
            cs_cmd+=" --security-opt=label=disable"
            cs_cmd+=" --mount=type=bind,source=${remote_data_dir},destination=/tmp"
            cs_cmd+=" --mount=type=bind,source=/lib/modules,destination=/lib/modules"
            cs_cmd+=" --mount=type=bind,source=/usr/src,destination=/usr/src"
            cs_cmd+=" ${image}"
        fi

        echo -e "About to run:\n${cs_cmd}\n"
        do_ssh $user@$host "${cs_cmd}"
        ssh_rc=$?
        if [ ${ssh_rc} -gt 0 ]; then
            echo "running ${osruntime} failed"
            exit 1
        fi

        let count=$count+1
    done
    echo "This endpoint deployed"
    echo
}

function move_remotehost_logs() {
    local this_cs_label remote_cs_log_file container_name
    mkdir -p "$client_server_logs_dir"
    for this_cs_label in ${clients[@]} ${servers[@]}; do
        if [ "${osruntime}" == "chroot" ]; then
            remote_cs_log_file="$remote_logs_dir/$this_cs_label.txt"
            pushd / >/dev/null
            do_scp "$user@$host:$remote_cs_log_file" / && \
                mv $remote_cs_log_file $client_server_logs_dir && \
                do_ssh $user@$host /bin/rm -r $remote_dir
            popd >/dev/null
        elif [ "${osruntime}" == "podman" ]; then
            container_name="${endpoint_label}_${run_id}"
            do_ssh $user@$host podman logs ${container_name} > "${client_server_logs_dir}/${this_cs_label}.txt"
        fi
    done
}

function endpoint_remotehost_cleanup() {
    move_remotehost_logs
    cleanup_osruntime
}

process_opts $@
process_remotehost_opts $endpoint_opts
init_common_dirs
remotehost_req_check
base_req_check
launch_osruntime
process_roadblocks remotehost
